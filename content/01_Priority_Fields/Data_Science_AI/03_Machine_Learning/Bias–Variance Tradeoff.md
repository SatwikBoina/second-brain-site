---
type: concept
domain: machine-learning
category: model-evaluation
status: evergreen
---

# Biasâ€“Variance Tradeoff

> The fundamental tradeoff between a modelâ€™s ability to **fit training data** (bias) and its **sensitivity to data fluctuations** (variance).

---

## 1. Core Idea

Any supervised learning model makes errors due to:

- **Bias** â†’ errors from incorrect assumptions
- **Variance** â†’ errors from sensitivity to training data

Improving one often worsens the other.

---

## 2. Bias

**Bias** measures how much the modelâ€™s predictions differ from the true underlying function *on average*.

### Characteristics
- High bias â†’ underfitting
- Model too simple
- Misses important patterns

### Examples
- Linear Regression on non-linear data
- Logistic Regression with poor features

ğŸ”— Related:
- [[Underfitting]]
- [[Linear Models â€” MOC]]

---

## 3. Variance

**Variance** measures how much model predictions change when trained on different datasets.

### Characteristics
- High variance â†’ overfitting
- Model too complex
- Fits noise instead of signal

### Examples
- Decision Trees without pruning
- k-NN with very small k

ğŸ”— Related:
- [[Overfitting]]
- [[Tree-Based Models â€” MOC]]

---

## 4. The Tradeoff

- Decreasing bias usually increases variance
- Decreasing variance usually increases bias
- Goal is **optimal balance**, not zero error

There is no universally best model â€” only best *for a dataset*.

---

## 5. Error Decomposition (Intuition)

Expected prediction error can be decomposed into:

- BiasÂ²
- Variance
- Irreducible noise

ğŸ”— Concept:
- [[Irreducible Error]]

---

## 6. How Model Complexity Affects the Tradeoff

| Model Complexity | Bias | Variance |
|-----------------|------|----------|
| Very simple | High | Low |
| Moderate | Balanced | Balanced |
| Very complex | Low | High |

ğŸ”— Related:
- [[Model Complexity]]

---

## 7. Algorithm-Wise Intuition

| Algorithm | Bias | Variance |
|--------|------|----------|
| Linear Regression | High | Low |
| Polynomial Regression (high degree) | Low | High |
| Decision Tree | Low | High |
| Random Forest | Medium | Low |
| Gradient Boosting | Low | Medium |
| k-NN (small k) | Low | High |
| k-NN (large k) | High | Low |
| Naive Bayes | High | Very Low |

---

## 8. Controlling Biasâ€“Variance

### Increase Bias / Reduce Variance
- Simpler models
- Regularization
- Fewer features
- More data

### Reduce Bias / Increase Variance
- More complex models
- Feature engineering
- Deeper trees
- Non-linear kernels

ğŸ”— Related:
- [[Regularization â€” MOC]]
- [[Feature Engineering]]

---

## 9. Role of Data Size

- Small datasets â†’ variance dominates
- Large datasets â†’ bias dominates

Adding data usually reduces variance, not bias.

---

## 10. Diagnostic Tools

- Learning curves
- Cross-validation
- Training vs validation error comparison

ğŸ”— Related:
- [[Learning Curves]]
- [[Cross Validation]]

---

## 11. Common Misconceptions

- âŒ High accuracy means low bias & variance  
- âŒ Overfitting = bad model always  
- âŒ One model fits all datasets  

The tradeoff is **context-dependent**.

---

## 12. Why This Concept Matters

Biasâ€“variance tradeoff explains:

- Why ensembles work
- Why regularization helps
- Why more data matters
- Why simpler models sometimes win

This is the **mental backbone of model selection**.

---

## Usage Notes

- This note should be linked by **every algorithm**
- Do NOT duplicate this explanation elsewhere
- Extend only via backlinks, not edits
