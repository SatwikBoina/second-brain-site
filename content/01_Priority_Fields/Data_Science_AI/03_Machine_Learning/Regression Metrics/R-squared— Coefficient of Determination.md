---
type: zettel
domain: machine-learning
category: regression
topic: evaluation-metric
status: draft
tags:
  - regression
  - evaluation-metrics
  - ML
---

---

## One-line idea
> Measures the proportion of variance in the target variable explained by the regression model.

---

## Formula

$$
R^2 =
1 -
\frac{SS_{res}}{SS_{tot}}


Where:


SS_{res} = \sum (y_i - \hat{y}_i)^2

SS_{tot} = \sum (y_i - \bar{y})^2

$$

---

## Intuition
- Compares model error with a **naive baseline model**
- Baseline model always predicts the **mean**
- RÂ² tells how much better the model is than predicting the mean

---

## Range
- $( -\infty \rightarrow 1)$

### Interpretation:
- **1** â†’ perfect model  
- **0** â†’ same as predicting mean  
- **< 0** â†’ worse than mean prediction  

---

## Unit
- Unitless (percentage of variance)

---

## Strengths
- Easy to interpret
- Scale-independent
- Useful for linear models
- Explains variance captured

---

## Limitations
- Does not measure prediction accuracy
- Sensitive to outliers
- Always increases when features are added
- Misleading for non-linear models
- Not suitable for model comparison alone

---

## Sensitive to Outliers?
- âœ… Yes
- Uses squared errors internally

---

## When to Use
- Linear regression diagnostics
- Explaining model performance
- Statistical reporting
- Comparing against baseline model

---

## When NOT to Use
- Forecast accuracy evaluation
- Time series forecasting
- Comparing models with different targets
- Non-linear ML models

---

## Business Interpretation
- RÂ² = 0.82

ðŸ‘‰ Model explains **82% of variability** in the target variable.


---

## Relationship to Other Metrics
- RÂ² is variance-based
- RMSE / MAE are error-based
- Adjusted RÂ² penalizes feature count
- High RÂ² â‰  good predictions

---

## Related Metrics
- [[Adjusted R-squared]]
---

## Key Takeaway
> RÂ² explains variance captured by the model â€” not how accurate the predictions are.

