---
type: moc
domain: machine-learning
category: classification
tags:
  - moc
  - regression
  - evaluation-metrics
  - ML
---

## ğŸ¯ Purpose
Central map to understand, compare, and choose **classification evaluation metrics** based on data imbalance, thresholds, probability outputs, and business cost.

---

## ğŸ”— Core Foundations
- [[Confusion Matrix]]
- [[Classification Threshold]]
- [[Probability vs Class Prediction]]
- [[Cost-Sensitive Classification]]

---
[[Classification Metrics - Prep]]

## ğŸ“ˆ Curve-Based Metrics

### ROC Metrics
- [[ROC Curve]]
- [[AUC ROC]]

---

### Precisionâ€“Recall Metrics
- [[Precision Recall Curve]]
- [[Average Precision]]

---

## ğŸ”¢ Probabilistic Metrics
- [[Log Loss]]
- [[Binary Cross Entropy]]
- [[Brier Score]]
- [[Calibration Curve]]
- [[Expected Calibration Error]]

---

## âš ï¸ Imbalanced Classification Metrics
- [[Balanced Accuracy]]
- [[Matthews Correlation Coefficient]]
- [[Cohenâ€™s Kappa]]
- [[Youdenâ€™s J Statistic]]

---

## ğŸ§® Threshold-Dependent Metrics
- [[KS Statistic]]
- [[Lift Chart]]
- [[Gain Chart]]
- [[Decile Analysis]]

---

## ğŸ§  Business-Oriented Metrics
- [[Cost Matrix]]
- [[Expected Profit]]
- [[Expected Loss]]
- [[Precision at K]]
- [[Recall at K]]
- [[Top-K Accuracy]]

---

## ğŸ”„ Multiclass Classification Metrics
- [[Macro Average]]
- [[Micro Average]]
- [[Weighted Average]]

Applied to:
- Precision
- Recall
- F1 Score
- ROC AUC (OvR / OvO)

---

## ğŸ§ª Model Comparison & Selection
- [[Threshold Optimization]]
- [[ROC vs PR Curve]]
- [[Metric Tradeoffs]]
- [[Choosing Classification Metrics]]

---

## ğŸ§  Conceptual Knowledge
- [[Why Accuracy Fails]]
- [[Precision Recall Tradeoff]]
- [[ROC Curve Pitfalls]]
- [[Threshold vs Probability]]
- [[Classification as Decision Theory]]

---

## ğŸ“š Advanced Topics
- [[Partial AUC]]
- [[Cost Curves]]
- [[Decision Curve Analysis]]
- [[Bayes Optimal Classifier]]
- [[Expected Utility Maximization]]

---

